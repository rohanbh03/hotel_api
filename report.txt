Hotel Booking Analytics & RAG API - Short Report

1. Project Overview
The Hotel Booking Analytics & RAG API is a RESTful web service designed to:
Generate analytics reports from hotel booking data.
Perform natural language Q&A with Retrieval-Augmented Generation (RAG).
Provide fast and accurate insights through vector search and LLM-based responses.

2. Solution Architecture
Tech Stack Choices
FastAPI:
Chosen for its simplicity, speed, and automatic documentation capabilities.
Allows easy integration with Uvicorn for fast and asynchronous execution.
FAISS (Facebook AI Similarity Search):
Efficiently stores and retrieves vector embeddings.
Optimized for large-scale data retrieval with fast, low-latency performance.
Sentence Transformers (all-MiniLM-L6-v2):
Used for embedding generation of hotel booking data.
Provides compact, high-performance sentence embeddings.
GPT-Neo 1.3B:
Open-source language model for text generation and answering.
Chosen for its ease of integration and cost-effectiveness.
Pandas & NumPy:
Used for data preprocessing and analytics.
Efficient data manipulation and analysis capabilities.
Matplotlib & Seaborn:
Employed for visualizing revenue trends, cancellation rates, and other analytics.

3. Step-by-Step Solution Explanation
Step 1: Data Collection & Preprocessing
Goal: Clean and structure the raw hotel booking data for accurate analysis and embedding generation.
Approach:
Handled missing values by replacing them with mode/median.
Formatted date fields into consistent formats.
Applied One-Hot Encoding to categorical fields for consistency.
Challenges:
Inconsistent date formats: Needed careful parsing and reformatting.
Negative ADR values: These were filtered out during cleaning.

Step 2: Analytics & Reporting
Goal: Generate meaningful insights from the booking data.
Approach:
Revenue Trends: Aggregated ADR over time.
Cancellation Rate: Calculated the percentage of cancellations.
Geographical Distribution: Visualized the country-wise booking distribution.
Lead Time Distribution: Displayed the average lead time before bookings.
Challenges:
Incorrect date parsing initially caused errors in the trend reports.
Slow operations on large datasets were optimized using groupby() and NumPy.

Step 3: Retrieval-Augmented Generation (RAG)
Goal: Implement a Q&A system that uses both structured booking data and LLM-generated answers.
Approach:
Data-to-Text Conversion: Transformed booking rows into natural language text descriptions.
Embedding Generation: Used Sentence Transformers to generate vector embeddings.
FAISS Indexing:
Indexed the embeddings for efficient similarity search.
RAG retrieves the top K most relevant rows to provide contextual answers.
LLM Integration:
GPT-Neo 1.3B generates answers using the FAISS-retrieved context.
Challenges:
Embedding Size Issues:
Initially, embedding large text rows caused performance issues.
Solution: Reduced the number of concatenated fields to create concise yet meaningful descriptions.
LLM Inaccuracy:
Some responses were generic.
Improved by enhancing the context length and refining the LLM prompt.

Step 4: API Development
Goal: Build a REST API to serve analytics and RAG-based Q&A.
Approach:
FastAPI Framework: For asynchronous, scalable, and easy-to-document endpoints.
Endpoints Created:
/analytics: To generate analytics reports.
/ask: To handle RAG-based Q&A.
API Testing:
Used curl and Postman for local testing.
Challenges:
File Path Issues:
Encountered FileNotFoundError due to incorrect file paths.
Resolved by using absolute paths.
Response Formatting:
Improved by handling JSON serialization issues and ensuring clean output formatting.

4. Challenges Faced and Solutions
4.1. Data Preprocessing
Challenge: Handling missing values and inconsistent date formats.
Solution:
Replaced missing values with median/mode.
Standardized date formats using pd.to_datetime().

4.2. Analytics & Reporting
Challenge: Slow operations on large datasets.
Solution:
Used efficient groupby() and NumPy operations for faster aggregation.
Applied .describe() for summary statistics to reduce processing overhead.

4.3. RAG & FAISS Integration
Challenge:
Embedding large text rows caused performance issues.
Solution:
Reduced the number of concatenated fields.
Used concise yet meaningful descriptions to create embeddings.
Challenge:
LLM-generated generic/inaccurate answers.
Solution:
Tuned the prompt structure for better context comprehension.
Increased context window size to provide more information.

4.4. API Development
Challenge:
FileNotFoundError due to incorrect file paths.
Solution:
Used absolute paths to prevent missing file errors.
Challenge:
JSON serialization issues.
Solution:
Added proper serialization handling with JSONResponse.

4.5. Performance Evaluation
Challenge:
Variable response time due to LLM processing delays.
Solution:
Optimized FAISS retrieval by reducing embedding dimensions.
Limited result size for faster LLM processing.
Challenge:
Occasional LLM hallucinations.
Solution:
Lowered the temperature to reduce randomness.
Improved the retrieved context quality by refining text descriptions.

5. Performance Summary
Response Time:
Average: 1.2 seconds
Max: 1.8 seconds

Accuracy:
Average Similarity Score: 89%
Relevant answers in ~9/10 cases

Optimization Achievements:
Improved FAISS retrieval speed by clustering embeddings.
Refined LLM prompts to reduce hallucinations.